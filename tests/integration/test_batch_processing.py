#!/usr/bin/env python3
"""
ë°°ì¹˜ ì²˜ë¦¬ í†µí•© í…ŒìŠ¤íŠ¸

quickstart.mdì˜ ì‹œë‚˜ë¦¬ì˜¤ 2ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
ë‹¤ì¤‘ í”„ë¡¬í”„íŠ¸ ë™ì‹œ ì²˜ë¦¬ ê²€ì¦ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

import sys
import time
import numpy as np
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

try:
    import requests
    from PIL import Image
except ImportError:
    print("âš ï¸ requests ë˜ëŠ” PIL ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤")
    print("ì„¤ì¹˜ ëª…ë ¹: uv add requests pillow")
    sys.exit(1)

class BatchProcessingTester:
    """ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤í„°"""

    def __init__(self, triton_url: str = "http://localhost:8000"):
        self.triton_url = triton_url
        self.bls_endpoint = f"{triton_url}/v2/models/bls/infer"

    def test_batch_processing(self, batch_size: int = 2) -> bool:
        """ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸

        Args:
            batch_size: ë°°ì¹˜ í¬ê¸°

        Returns:
            bool: í…ŒìŠ¤íŠ¸ ì„±ê³µ ì—¬ë¶€
        """
        print(f"\nğŸ“‹ ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ (ë°°ì¹˜ í¬ê¸°: {batch_size})")

        # quickstart.mdì˜ ì˜ˆì œ í”„ë¡¬í”„íŠ¸ë“¤ ì‚¬ìš©
        prompts = [
            "A beautiful landscape with mountains",
            "A futuristic city with flying cars"
        ]

        if batch_size > 2:
            # ë°°ì¹˜ í¬ê¸°ê°€ 2ë³´ë‹¤ í¬ë©´ ì¶”ê°€ í”„ë¡¬í”„íŠ¸ ìƒì„±
            for i in range(2, batch_size):
                prompts.append(f"Test prompt {i+1}")

        prompts = prompts[:batch_size]  # ë°°ì¹˜ í¬ê¸°ì— ë§ê²Œ ìë¥´ê¸°

        payload = {
            "inputs": [
                {
                    "name": "prompt",
                    "shape": [batch_size],
                    "datatype": "BYTES",
                    "data": prompts
                },
                {
                    "name": "num_inference_steps",
                    "shape": [1],
                    "datatype": "INT32",
                    "data": [4]
                },
                {
                    "name": "guidance_scale",
                    "shape": [1],
                    "datatype": "FP32",
                    "data": [0.0]
                }
            ]
        }

        try:
            print(f"ğŸ”„ BLS ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ: {self.bls_endpoint}")
            print(f"ğŸ“ í”„ë¡¬í”„íŠ¸ë“¤:")
            for i, prompt in enumerate(prompts):
                print(f"  {i+1}. {prompt}")

            start_time = time.time()
            response = requests.post(self.bls_endpoint, json=payload, timeout=240)
            elapsed_time = time.time() - start_time

            if response.status_code != 200:
                print(f"âŒ API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}")
                print(f"ì‘ë‹µ ë‚´ìš©: {response.text}")
                return False

            result = response.json()
            print(f"âœ… API í˜¸ì¶œ ì„±ê³µ (ì†Œìš”ì‹œê°„: {elapsed_time:.2f}ì´ˆ)")

            # ì‘ë‹µ êµ¬ì¡° ê²€ì¦
            if "outputs" not in result:
                print("âŒ ì‘ë‹µì— 'outputs' í•„ë“œê°€ ì—†ìŒ")
                return False

            image_output = None
            for output in result["outputs"]:
                if output.get("name") == "images":
                    image_output = output
                    break

            if image_output is None:
                print("âŒ ì‘ë‹µì— 'images' ì¶œë ¥ì´ ì—†ìŒ")
                return False

            # ë°°ì¹˜ í¬ê¸° ê²€ì¦
            image_shape = image_output["shape"]
            expected_batch_size = batch_size
            actual_batch_size = image_shape[0]

            if actual_batch_size != expected_batch_size:
                print(f"âŒ ë°°ì¹˜ í¬ê¸° ë¶ˆì¼ì¹˜: {actual_batch_size} != {expected_batch_size}")
                return False

            print(f"âœ… ë°°ì¹˜ í¬ê¸° ê²€ì¦ í†µê³¼: {actual_batch_size}")
            print(f"ğŸ“Š ìƒì„±ëœ ì´ë¯¸ì§€ í˜•íƒœ: {image_shape}")

            # ì´ë¯¸ì§€ ë°ì´í„° ê²€ì¦
            image_data = np.array(image_output["data"])
            expected_data_size = np.prod(image_shape)

            if len(image_data) != expected_data_size:
                print(f"âŒ ì´ë¯¸ì§€ ë°ì´í„° í¬ê¸° ë¶ˆì¼ì¹˜: {len(image_data)} != {expected_data_size}")
                return False

            print(f"âœ… ì´ë¯¸ì§€ ë°ì´í„° í¬ê¸° ê²€ì¦ í†µê³¼: {len(image_data)}")

            # ê° ë°°ì¹˜ë³„ ì´ë¯¸ì§€ ì €ì¥
            try:
                image_array = image_data.reshape(image_shape)

                for i in range(batch_size):
                    # ê° ì´ë¯¸ì§€ ì¶”ì¶œ ë° ì €ì¥
                    single_image = image_array[i]
                    image_rgb = (single_image.transpose(1, 2, 0) * 255).astype(np.uint8)

                    # ê°’ ë²”ìœ„ í™•ì¸
                    min_val, max_val = image_rgb.min(), image_rgb.max()
                    print(f"ğŸ“Š ì´ë¯¸ì§€ {i+1} í”½ì…€ ê°’ ë²”ìœ„: {min_val} ~ {max_val}")

                    image = Image.fromarray(image_rgb)
                    output_path = PROJECT_ROOT / f"test_batch_output_{i+1}.png"
                    image.save(output_path)
                    print(f"ğŸ’¾ ì´ë¯¸ì§€ {i+1} ì €ì¥ ì™„ë£Œ: {output_path}")

            except Exception as e:
                print(f"âš ï¸ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}")

            print("âœ… ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
            return True

        except requests.Timeout:
            print("âŒ ìš”ì²­ íƒ€ì„ì•„ì›ƒ (240ì´ˆ)")
            return False
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            return False

    def test_memory_efficiency(self) -> bool:
        """ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸"""
        print("\nğŸ“‹ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸")

        try:
            # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§
            import psutil
            process = psutil.Process()
            initial_memory = process.memory_info().rss / 1024 / 1024  # MB

            print(f"ğŸ“Š ì´ˆê¸° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {initial_memory:.2f} MB")

            # ì‘ì€ ë°°ì¹˜ í…ŒìŠ¤íŠ¸
            small_batch_success = self.test_batch_processing(batch_size=2)

            current_memory = process.memory_info().rss / 1024 / 1024
            memory_increase = current_memory - initial_memory

            print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ í›„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {current_memory:.2f} MB")
            print(f"ğŸ“Š ë©”ëª¨ë¦¬ ì¦ê°€ëŸ‰: {memory_increase:.2f} MB")

            # DLPack ìµœì í™” íš¨ê³¼ ê²€ì¦ (CPU ë©”ëª¨ë¦¬ ì¦ê°€ê°€ ìµœì†Œí™”ë˜ì–´ì•¼ í•¨)
            if memory_increase < 200:  # 200MB ì´í•˜ë¡œ ì œí•œ
                print("âœ… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ íš¨ìœ¨ì ì…ë‹ˆë‹¤")
                return small_batch_success
            else:
                print("âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤ (DLPack ìµœì í™” í™•ì¸ í•„ìš”)")
                return small_batch_success

        except ImportError:
            print("âš ï¸ psutil ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ì–´ ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ì„ ê±´ë„ˆëœë‹ˆë‹¤")
            return self.test_batch_processing(batch_size=2)

def main():
    """ë°°ì¹˜ ì²˜ë¦¬ í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ ë°°ì¹˜ ì²˜ë¦¬ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)

    tester = BatchProcessingTester()

    # 1. ì„œë²„ ìƒíƒœ í™•ì¸
    try:
        response = requests.get(f"{tester.triton_url}/v2/health/ready", timeout=5)
        if response.status_code != 200:
            print("âŒ Triton ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            print("\nğŸ’¡ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì „ Triton ì„œë²„ë¥¼ ì‹œì‘í•˜ì„¸ìš”")
            return False
        print("âœ… Triton ì„œë²„ ì—°ê²° ì„±ê³µ")
    except Exception:
        print("âŒ Triton ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return False

    # 2. ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ë“¤
    test_results = []

    # ê¸°ë³¸ ë°°ì¹˜ í…ŒìŠ¤íŠ¸ (ë°°ì¹˜ í¬ê¸° 2)
    test_results.append(tester.test_batch_processing(batch_size=2))

    # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸
    test_results.append(tester.test_memory_efficiency())

    # ì¶”ê°€: ë” í° ë°°ì¹˜ í…ŒìŠ¤íŠ¸ (ì„ íƒì )
    print("\nğŸ“‹ ì„ íƒì  ëŒ€ìš©ëŸ‰ ë°°ì¹˜ í…ŒìŠ¤íŠ¸")
    try:
        large_batch_success = tester.test_batch_processing(batch_size=4)
        test_results.append(large_batch_success)
        if large_batch_success:
            print("âœ… ëŒ€ìš©ëŸ‰ ë°°ì¹˜ ì²˜ë¦¬ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤")
        else:
            print("âš ï¸ ëŒ€ìš©ëŸ‰ ë°°ì¹˜ ì²˜ë¦¬ì—ì„œ ë¬¸ì œ ë°œìƒ (GPU ë©”ëª¨ë¦¬ ì œí•œ ê°€ëŠ¥ì„±)")
    except Exception as e:
        print(f"âš ï¸ ëŒ€ìš©ëŸ‰ ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ê±´ë„ˆëœ€: {e}")

    print("\n" + "=" * 50)
    success_count = sum(test_results)
    total_count = len(test_results)

    if success_count == total_count:
        print("ğŸ‰ ë°°ì¹˜ ì²˜ë¦¬ í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    else:
        print(f"âš ï¸ {total_count - success_count}ê°œ í…ŒìŠ¤íŠ¸ì—ì„œ ë¬¸ì œ ë°œìƒ")

    return success_count > 0

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)