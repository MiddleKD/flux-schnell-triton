name: "clip_encoder"
platform: "python"
max_batch_size: 16

# 입력 정의
input [
  {
    name: "input_ids"
    data_type: TYPE_INT64
    dims: [ 77 ]  # CLIP max sequence length
  },
  {
    name: "attention_mask"
    data_type: TYPE_INT32
    dims: [ 77 ]
    optional: true
  }
]

# 출력 정의
output [
  {
    name: "pooled_embeds"
    data_type: TYPE_FP32
    dims: [ 768 ]  # CLIP embedding dimension
  }
]

# GPU 인스턴스
instance_group [
  {
    count: 1
    kind: KIND_GPU
    gpus: [ 0 ]
  }
]

# 동적 배치 설정
dynamic_batching {
  max_queue_delay_microseconds: 50000  # 50ms
  preferred_batch_size: [ 4, 8, 16 ]
}

# 모델 파라미터
parameters [
  {
    key: "model_name"
    value: { string_value: "black-forest-labs/FLUX.1-schnell" }
  },
  {
    key: "max_sequence_length"
    value: { string_value: "77" }
  },
  {
    key: "embedding_dim"
    value: { string_value: "768" }
  }
]

# 버전 정책: 최신 1개 버전
version_policy: { latest { num_versions: 1 } }

# 모델 워밍업
model_warmup [
  {
    name: "clip_warmup"
    batch_size: 1
    inputs [
      {
        key: "input_ids"
        value: {
          input_data_type: TYPE_INT64
          dims: [ 77 ]
          int64_data: [ 49406, 320, 2368, 5193, 320, 1320, 515, 1139, 7593, 1079, 49407 ]
          # 나머지는 0으로 패딩 가능
        }
      },
      {
        key: "attention_mask"
        value: {
          input_data_type: TYPE_INT32
          dims: [ 77 ]
          int32_data: [1,1,1,1,1,1,1,1,1,1,1]  # 나머지는 0으로 패딩 가능
        }
      }
    ]
  }
]
