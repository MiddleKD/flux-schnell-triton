# T5 Text Encoder Configuration
# T5 모델을 사용한 텍스트 시퀀스 인코딩 서비스
# GPU에서 실행되며 텍스트를 sequence embeddings로 변환

name: "t5_encoder"
platform: "python"
max_batch_size: 8

input [
  {
    name: "input_ids"
    data_type: TYPE_INT64
    dims: [ 512 ]  # T5 max sequence length
  },
  {
    name: "attention_mask"
    data_type: TYPE_INT32
    dims: [ 512 ]
    optional: true
  }
]

output [
  {
    name: "sequence_embeds"
    data_type: TYPE_FP32
    dims: [ 512, 4096 ]  # [seq_len, embedding_dim]
  },
  {
    name: "text_ids"
    data_type: TYPE_FP32
    dims: [ 512, 3 ]  # 텍스트 위치 ID
  }
]

# GPU 인스턴스 설정 (T5는 메모리를 많이 사용)
instance_group [
  {
    count: 1
    kind: KIND_GPU
    gpus: [ 0 ]
  }
]

# 동적 배치 설정 (T5는 큰 모델이므로 작은 배치 선호)
dynamic_batching {
  max_queue_delay_microseconds: 100000  # 100ms
  preferred_batch_size: [ 2, 4 ]
}

# T5 모델 관련 파라미터들
parameters [
  {
    key: "model_name"
    value: { string_value: "google/t5-v1_1-xxl" }
  },
  {
    key: "max_sequence_length"
    value: { string_value: "512" }
  },
  {
    key: "embedding_dim"
    value: { string_value: "4096" }
  }
]

# 버전 정책
version_policy: { latest { num_versions: 1 } }

# 최적화 설정
optimization {
  cuda {
    graphs: true
    graph_spec {
      batch_size: 1
      input [
        {
          key: "input_ids"
          value: {
            dims: [ 512 ]
          }
        }
      ]
    }
    graph_spec {
      batch_size: 2
      input [
        {
          key: "input_ids"
          value: {
            dims: [ 512 ]
          }
        }
      ]
    }
  }
}

# 모델 워밍업
model_warmup [
  {
    name: "t5_warmup"
    batch_size: 1
    inputs [
      {
        key: "input_ids"
        value: {
          input_data_type: TYPE_INT64
          dims: [ 512 ]
          int64_data: [ 0, 71, 1712, 3, 9, 1320, 24, 845, 7593, 296, 1 ]
          # 나머지는 0으로 패딩 (실제로는 512개 모두 필요)
        }
      }
    ]
  }
]